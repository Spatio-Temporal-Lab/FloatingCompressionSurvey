{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04eb7175",
   "metadata": {},
   "source": [
    "# Datasets Preprocessing\n",
    "\n",
    "This Notebook contains the preprocessing of the raw datasets after being downloaded from the web. Our benchmarks and scripts expects a `.bin` file with only the doubles (no column header) in their IEEE 754 (`double`) representation. This notebook transforms each of the 30 datasets into this format.\n",
    "\n",
    "- Version: 0.0.1     \n",
    "- Last Edited: 15/04/2023\n",
    "\n",
    "## Dependencies\n",
    "To use this notebook you need Python (>3.7), Jupyter Notebook and the Libraries `pandas` and `numpy` installed (https://pandas.pydata.org/docs/). To install them, execute the next two cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d408352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566b71d",
   "metadata": {},
   "source": [
    "# NEON Datasets\n",
    "\n",
    "When downloaded and unzipped, these datasets are scattered across many directories and files. The following cells process every directory structure to build the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1fded",
   "metadata": {},
   "source": [
    "## PM10-Dust\n",
    "Download URL: https://doi.org/10.48443/4E6X-V373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "008721b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'PM10Median': []})\n",
    "root = './NEON_size-dust-particulate/'\n",
    "dates = os.listdir(root)\n",
    "dates.sort()\n",
    "for date in dates:\n",
    "    curr_path = root + date + '/'\n",
    "    if not os.path.isdir(curr_path): continue\n",
    "    enter = False\n",
    "    for filename in os.listdir(curr_path):\n",
    "        if '30_minutes' in filename and filename.endswith('.csv') and ('basic.2020' in filename or 'basic.2021' in filename):\n",
    "            enter = True\n",
    "            filename_path = curr_path + filename\n",
    "            df_tmp = pd.read_csv(filename_path)\n",
    "            df_tmp = df_tmp[['PM10Median']].dropna()\n",
    "            df = pd.concat([df, df_tmp], copy=False)\n",
    "    if enter == False:\n",
    "        print(curr_path)\n",
    "df['PM10Median'].values.tofile('neon_pm10_dust.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b6fa55",
   "metadata": {},
   "source": [
    "## Dew-Point-Temp\n",
    "\n",
    "Download URL: https://doi.org/10.48443/Z99V-0502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a7814a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'dewTempMean': []})\n",
    "root = './NEON_rel-humidity-buoy/'\n",
    "dates = os.listdir(root)\n",
    "dates.sort()\n",
    "for date in dates:\n",
    "    curr_path = root + date + '/'\n",
    "    if not os.path.isdir(curr_path): continue\n",
    "    enter = False\n",
    "    for filename in os.listdir(curr_path):\n",
    "        if '1min' in filename and filename.endswith('.csv') and ('basic.2020' in filename or 'basic.2021' in filename):\n",
    "            enter = True\n",
    "            filename_path = curr_path + filename\n",
    "            df_tmp = pd.read_csv(filename_path)\n",
    "            df_tmp = df_tmp[['dewTempMean']].dropna()\n",
    "            df = pd.concat([df, df_tmp], copy=False)\n",
    "    if enter == False:\n",
    "        print(curr_path)\n",
    "df['dewTempMean'].values.tofile('neon_dew_point_temp.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e94d8",
   "metadata": {},
   "source": [
    "## Air Pressure\n",
    "\n",
    "Download URL: https://doi.org/10.48443/RXR7-PP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef09da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'staPresMean': []})\n",
    "root = './NEON_pressure-air/'\n",
    "dates = os.listdir(root)\n",
    "dates.sort()\n",
    "for date in dates:\n",
    "    curr_path = root + date + '/'\n",
    "    if not os.path.isdir(curr_path): continue\n",
    "    enter = False\n",
    "    for filename in os.listdir(curr_path):\n",
    "        if '1min' in filename and filename.endswith('.csv') and ('basic.2020' in filename or 'basic.2021' in filename):\n",
    "            enter = True\n",
    "            filename_path = curr_path + filename\n",
    "            df_tmp = pd.read_csv(filename_path)\n",
    "            df_tmp = df_tmp[['staPresMean']].dropna()\n",
    "            df = pd.concat([df, df_tmp], copy=False)\n",
    "    if enter == False:\n",
    "        print(curr_path)\n",
    "df['staPresMean'].values.tofile('neon_air_pressure.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e502a6",
   "metadata": {},
   "source": [
    "## Wind Direction\n",
    "\n",
    "Download URL: https://doi.org/10.48443/S9YA-ZC81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd1c0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'windDirMean': []})\n",
    "root = './NEON_wind-2d/'\n",
    "dates = os.listdir(root)\n",
    "dates.sort()\n",
    "for date in dates:\n",
    "    curr_path = root + date + '/'\n",
    "    if not os.path.isdir(curr_path): continue\n",
    "    enter = False\n",
    "    for filename in os.listdir(curr_path):\n",
    "        if '2min' in filename and filename.endswith('.csv') and ('basic.2020' in filename or 'basic.2021' in filename):\n",
    "            enter = True\n",
    "            filename_path = curr_path + filename\n",
    "            df_tmp = pd.read_csv(filename_path)\n",
    "            df_tmp = df_tmp[['windDirMean']].dropna()\n",
    "            df = pd.concat([df, df_tmp], copy=False)\n",
    "    if enter == False:\n",
    "        print(curr_path)\n",
    "df['windDirMean'].values.tofile('neon_wind_dir.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b89c44",
   "metadata": {},
   "source": [
    "## IR-Bio-Temp\n",
    "\n",
    "Download URL: https://doi.org/10.48443/JNWY-B177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93b4125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'bioTempMean': []})\n",
    "root = './NEON_temp-bio/'\n",
    "dates = os.listdir(root)\n",
    "dates.sort()\n",
    "for date in dates:\n",
    "    curr_path = root + date + '/'\n",
    "    if not os.path.isdir(curr_path): continue\n",
    "    enter = False\n",
    "    for filename in os.listdir(curr_path):\n",
    "        if '1_minute' in filename and filename.endswith('.csv') and ('basic.2020' in filename or 'basic.2021' in filename):\n",
    "            enter = True\n",
    "            filename_path = curr_path + filename\n",
    "            df_tmp = pd.read_csv(filename_path)\n",
    "            df_tmp = df_tmp[['bioTempMean']].dropna()\n",
    "            df = pd.concat([df, df_tmp], copy=False)\n",
    "    if enter == False:\n",
    "        print(curr_path)\n",
    "df['bioTempMean'].values.tofile('neon_bio_temp.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bac3ce",
   "metadata": {},
   "source": [
    "# STOCKS Datasets\n",
    "\n",
    "When downloaded and unzipped, these datasets are scattered across many directories and files. The following cells process every directory structure to build the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650204b2",
   "metadata": {},
   "source": [
    "## Stocks USA / DE / UK\n",
    "\n",
    "Download URL: https://zenodo.org/record/3886895#%23.ZDBBKuxBz0r\n",
    "\n",
    "- Create the directory with the name inside the variable `tmp_dir`. We will save temporary CSVs on this directory that will then be joined (we do this to optimize the process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c72f0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['Germany', 'United Kingdom', 'USA']\n",
    "tmp_dir = 'stocks_tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b01cc3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01012019\n",
      "01022019\n",
      "01032019\n",
      "01042019\n",
      "01012019\n",
      "01022019\n",
      "01032019\n",
      "01042019\n",
      "01012019\n",
      "01022019\n",
      "01032019\n",
      "01042019\n"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    file_prefix = 'Stocks ' + country\n",
    "    df = pd.DataFrame({2: []})\n",
    "    root = './FinancialData/quotes/'\n",
    "    dates = os.listdir(root)\n",
    "    dates.sort()\n",
    "    x = 0\n",
    "    for date in dates:\n",
    "        df_date = pd.DataFrame({2: []})\n",
    "        if not date.isdigit(): continue\n",
    "        curr_path = root + date + '/'\n",
    "        print(date)\n",
    "        for filename in os.listdir(curr_path):\n",
    "            if filename.startswith(file_prefix) and filename.endswith('.zip'):\n",
    "                filename_path = curr_path + filename\n",
    "                df_tmp = pd.read_csv(filename_path, compression='zip', header=None)\n",
    "                df_tmp = df_tmp[[2]]\n",
    "                df_date = pd.concat([df_date, df_tmp], copy=False)\n",
    "        df_date.to_csv('./' + tmp_dir + '/stocks_' + country + '_' + date + \".csv\", index=False, header=['value'])\n",
    "        if x == 3:\n",
    "            break\n",
    "        x+=1\n",
    "    dates = os.listdir(tmp_dir)\n",
    "    dates.sort()\n",
    "    df_list = []\n",
    "    for date in dates:\n",
    "        if country not in date:\n",
    "            continue\n",
    "        curr_path = tmp_dir + '/' + date\n",
    "        df = pd.read_csv(curr_path)\n",
    "        df_list.append(df)\n",
    "    df_final = pd.concat(df_list)\n",
    "    df_final['value'].values.tofile('stocks_' + country + '.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634ba80",
   "metadata": {},
   "source": [
    "# Public BI Benchmark\n",
    "Reference: https://github.com/cwida/public_bi_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483ad33",
   "metadata": {},
   "source": [
    "## CommonGov\n",
    "Download URL: https://homepages.cwi.nl/~boncz/PublicBIbenchmark/CommonGovernment/\n",
    "\n",
    "Download each of the files inside the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b472225",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov1 = pd.read_csv('./CommonGovernment_1.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov2 = pd.read_csv('./CommonGovernment_2.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov3 = pd.read_csv('./CommonGovernment_3.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov4 = pd.read_csv('./CommonGovernment_4.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov5 = pd.read_csv('./CommonGovernment_5.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov6 = pd.read_csv('./CommonGovernment_6.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov7 = pd.read_csv('./CommonGovernment_7.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov8 = pd.read_csv('./CommonGovernment_8.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov9 = pd.read_csv('./CommonGovernment_9.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov10 = pd.read_csv('./CommonGovernment_10.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov11 = pd.read_csv('./CommonGovernment_11.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov12 = pd.read_csv('./CommonGovernment_12.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov13 = pd.read_csv('./CommonGovernment_13.csv.bz2', header=None, sep='|', usecols=[9, 25, 29, 30, 39])\n",
    "gov = pd.concat([gov1, gov2, gov3, gov4, gov5, gov6, gov7, gov8, gov9, gov10, gov11, gov12, gov13])\n",
    "gov = gov.dropna()\n",
    "gov[9].values.tofile('gov10.bin')\n",
    "gov[25].values.tofile('gov26.bin')\n",
    "gov[29].values.tofile('gov30.bin') \n",
    "gov[30].values.tofile('gov31.bin') \n",
    "gov[39].values.tofile('gov40.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18588ffd",
   "metadata": {},
   "source": [
    "# Medicare\n",
    "Download URL: https://homepages.cwi.nl/~boncz/PublicBIbenchmark/Medicare3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6142f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare1 = pd.read_csv('./Medicare3_1.csv.bz2', header=None, sep='|', usecols=[0, 8], dtype=np.float64)\n",
    "medicare = medicare1.dropna()\n",
    "medicare[0].values.tofile('medicare1.bin')\n",
    "medicare[8].values.tofile('medicare9.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97db032",
   "metadata": {},
   "source": [
    "# CMSProvider\n",
    "\n",
    "Download URL: https://homepages.cwi.nl/~boncz/PublicBIbenchmark/CMSprovider/   \n",
    "\n",
    "Download each of the files inside the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b5224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms1 = pd.read_csv('./CMSprovider_1.csv.bz2', header=None, sep='|', usecols=[0, 8, 24], dtype=np.float64)\n",
    "cms2 = pd.read_csv('./CMSprovider_2.csv.bz2', header=None, sep='|', usecols=[0, 8, 24], dtype=np.float64)\n",
    "cms = pd.concat([cms1, cms2])\n",
    "cms = cms.dropna()\n",
    "cms[0].values.tofile('cms1.bin')\n",
    "cms[8].values.tofile('cms9.bin')\n",
    "cms[24].values.tofile('cms25.bin') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49b170",
   "metadata": {},
   "source": [
    "# NYC\n",
    "\n",
    "Download URL: https://homepages.cwi.nl/~boncz/PublicBIbenchmark/NYC/\n",
    "\n",
    "Download each of the files inside the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74820721",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc1 = pd.read_csv('./NYC_1.csv.bz2', header=None, sep='|', usecols=[28])\n",
    "nyc2 = pd.read_csv('./NYC_2.csv.bz2', header=None, sep='|', usecols=[28])\n",
    "nyc = pd.concat([nyc1, nyc2])\n",
    "nyc = nyc.dropna()\n",
    "nyc[28].values.tofile('nyc29.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b579d7",
   "metadata": {},
   "source": [
    "# Arade\n",
    "\n",
    "Download URL: https://homepages.cwi.nl/~boncz/PublicBIbenchmark/Arade/   \n",
    "\n",
    "Download each of the files inside the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ac52650",
   "metadata": {},
   "outputs": [],
   "source": [
    "arade = pd.read_csv('./Arade_1.csv.bz2', sep='|', header=None)\n",
    "arade[3].values.tofile('arade4.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbbe94",
   "metadata": {},
   "source": [
    "# The Other Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a6346",
   "metadata": {},
   "source": [
    "# POI (Lat - Lon)\n",
    "\n",
    "Download URL: https://www.kaggle.com/datasets/ehallmar/points-of-interest-poi-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dac69b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>latitude_radian</th>\n",
       "      <th>longitude_radian</th>\n",
       "      <th>num_links</th>\n",
       "      <th>links</th>\n",
       "      <th>num_categories</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YAYCHI, WEST AZERBAIJAN</td>\n",
       "      <td>0.683175</td>\n",
       "      <td>0.778053</td>\n",
       "      <td>13</td>\n",
       "      <td>Baba Jik Rural District; West Azerbaijan Provi...</td>\n",
       "      <td>1</td>\n",
       "      <td>POPULATED PLACES IN CHALDORAN COUNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOUNT FISKE GLACIER</td>\n",
       "      <td>0.648196</td>\n",
       "      <td>-2.071114</td>\n",
       "      <td>9</td>\n",
       "      <td>Mount Fiske; Mount Warlow Glacier; U.S. state;...</td>\n",
       "      <td>3</td>\n",
       "      <td>GLACIERS OF THE SIERRA NEVADA (U.S.); GLACIERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALATONA</td>\n",
       "      <td>0.258356</td>\n",
       "      <td>-0.103606</td>\n",
       "      <td>10</td>\n",
       "      <td>Diabaly; Alatona Irrigation Project; Mali; Nio...</td>\n",
       "      <td>2</td>\n",
       "      <td>POPULATED PLACES IN SÉGOU REGION; IRRIGATION P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEMBA ISLAND</td>\n",
       "      <td>-0.090175</td>\n",
       "      <td>0.694350</td>\n",
       "      <td>43</td>\n",
       "      <td>Malaysia Airlines Flight 370; Arusha; Chake Ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>PEMBA ISLAND; ISLANDS OF TANZANIA; ISLANDS OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MBOLO</td>\n",
       "      <td>0.149517</td>\n",
       "      <td>0.359829</td>\n",
       "      <td>6</td>\n",
       "      <td>UTC; Sub-prefectures of the Central African Re...</td>\n",
       "      <td>2</td>\n",
       "      <td>N'DÉLÉ; POPULATED PLACES IN BAMINGUI-BANGORAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424200</th>\n",
       "      <td>PITTSFIELD TOWNSHIP, LORAIN COUNTY, OHIO</td>\n",
       "      <td>0.719842</td>\n",
       "      <td>-1.434913</td>\n",
       "      <td>28</td>\n",
       "      <td>Oberlin, Ohio; List of sovereign states; Civil...</td>\n",
       "      <td>1</td>\n",
       "      <td>TOWNSHIPS IN LORAIN COUNTY, OHIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424201</th>\n",
       "      <td>KEVIN BARTLETT RESERVE</td>\n",
       "      <td>-0.660297</td>\n",
       "      <td>2.531149</td>\n",
       "      <td>9</td>\n",
       "      <td>Burnley, Victoria; Collingwood City F.C.; Rich...</td>\n",
       "      <td>2</td>\n",
       "      <td>SOCCER VENUES IN AUSTRALIA; SPORTS VENUES IN M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424202</th>\n",
       "      <td>WEST SPRINGFIELD, VIRGINIA</td>\n",
       "      <td>0.676984</td>\n",
       "      <td>-1.347966</td>\n",
       "      <td>35</td>\n",
       "      <td>Fairfax County, Virginia; List of sovereign st...</td>\n",
       "      <td>4</td>\n",
       "      <td>CENSUS-DESIGNATED PLACES IN FAIRFAX COUNTY, VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424203</th>\n",
       "      <td>GLEN ROCK HISTORIC DISTRICT</td>\n",
       "      <td>0.694515</td>\n",
       "      <td>-1.339240</td>\n",
       "      <td>6</td>\n",
       "      <td>York County, Pennsylvania; Historic district (...</td>\n",
       "      <td>4</td>\n",
       "      <td>HISTORIC DISTRICTS ON THE NATIONAL REGISTER OF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424204</th>\n",
       "      <td>PURSAT PROVINCE</td>\n",
       "      <td>0.218748</td>\n",
       "      <td>1.813688</td>\n",
       "      <td>33</td>\n",
       "      <td>Cambodia; List of sovereign states; Phnom Penh...</td>\n",
       "      <td>2</td>\n",
       "      <td>PROVINCES OF CAMBODIA; PURSAT PROVINCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name  latitude_radian  \\\n",
       "0                        YAYCHI, WEST AZERBAIJAN         0.683175   \n",
       "1                            MOUNT FISKE GLACIER         0.648196   \n",
       "2                                        ALATONA         0.258356   \n",
       "3                                   PEMBA ISLAND        -0.090175   \n",
       "4                                          MBOLO         0.149517   \n",
       "...                                          ...              ...   \n",
       "424200  PITTSFIELD TOWNSHIP, LORAIN COUNTY, OHIO         0.719842   \n",
       "424201                    KEVIN BARTLETT RESERVE        -0.660297   \n",
       "424202                WEST SPRINGFIELD, VIRGINIA         0.676984   \n",
       "424203               GLEN ROCK HISTORIC DISTRICT         0.694515   \n",
       "424204                           PURSAT PROVINCE         0.218748   \n",
       "\n",
       "        longitude_radian  num_links  \\\n",
       "0               0.778053         13   \n",
       "1              -2.071114          9   \n",
       "2              -0.103606         10   \n",
       "3               0.694350         43   \n",
       "4               0.359829          6   \n",
       "...                  ...        ...   \n",
       "424200         -1.434913         28   \n",
       "424201          2.531149          9   \n",
       "424202         -1.347966         35   \n",
       "424203         -1.339240          6   \n",
       "424204          1.813688         33   \n",
       "\n",
       "                                                    links  num_categories  \\\n",
       "0       Baba Jik Rural District; West Azerbaijan Provi...               1   \n",
       "1       Mount Fiske; Mount Warlow Glacier; U.S. state;...               3   \n",
       "2       Diabaly; Alatona Irrigation Project; Mali; Nio...               2   \n",
       "3       Malaysia Airlines Flight 370; Arusha; Chake Ch...               5   \n",
       "4       UTC; Sub-prefectures of the Central African Re...               2   \n",
       "...                                                   ...             ...   \n",
       "424200  Oberlin, Ohio; List of sovereign states; Civil...               1   \n",
       "424201  Burnley, Victoria; Collingwood City F.C.; Rich...               2   \n",
       "424202  Fairfax County, Virginia; List of sovereign st...               4   \n",
       "424203  York County, Pennsylvania; Historic district (...               4   \n",
       "424204  Cambodia; List of sovereign states; Phnom Penh...               2   \n",
       "\n",
       "                                               categories  \n",
       "0                    POPULATED PLACES IN CHALDORAN COUNTY  \n",
       "1       GLACIERS OF THE SIERRA NEVADA (U.S.); GLACIERS...  \n",
       "2       POPULATED PLACES IN SÉGOU REGION; IRRIGATION P...  \n",
       "3       PEMBA ISLAND; ISLANDS OF TANZANIA; ISLANDS OF ...  \n",
       "4           N'DÉLÉ; POPULATED PLACES IN BAMINGUI-BANGORAN  \n",
       "...                                                   ...  \n",
       "424200                   TOWNSHIPS IN LORAIN COUNTY, OHIO  \n",
       "424201  SOCCER VENUES IN AUSTRALIA; SPORTS VENUES IN M...  \n",
       "424202  CENSUS-DESIGNATED PLACES IN FAIRFAX COUNTY, VI...  \n",
       "424203  HISTORIC DISTRICTS ON THE NATIONAL REGISTER OF...  \n",
       "424204             PROVINCES OF CAMBODIA; PURSAT PROVINCE  \n",
       "\n",
       "[424205 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi = pd.read_csv('./poi.csv')\n",
    "poi['latitude_radian'].values.tofile('poi_lat.bin')\n",
    "poi['longitude_radian'].values.tofile('poi_lon.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b301c",
   "metadata": {},
   "source": [
    "## Food Prices\n",
    "\n",
    "Download URL: https://data.humdata.org/dataset/wfp-food-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3607786",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_prices_df = pd.read_csv('wfpvam_foodprices.csv')\n",
    "food_prices_df['mp_price'].values.tofile('food_prices.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3545f3",
   "metadata": {},
   "source": [
    "## Bird-migration\n",
    "\n",
    "Download URL: https://github.com/influxdata/influxdb2-sample-data/blob/master/bird-migration-data/bird-migration.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28bb3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_migration_df = pd.read_csv('./bird_migration.csv', skiprows=3)\n",
    "bird_migration_df['_value'].values.tofile('bird_migration_f.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b8afa",
   "metadata": {},
   "source": [
    "## Bitcoin-price\n",
    "\n",
    "Download URL: https://raw.githubusercontent.com/influxdata/influxdb2-sample-data/master/bitcoin-price-data/bitcoin-historical-annotated.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6835ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_price_df = pd.read_csv('./bitcoin.csv', skiprows=3)\n",
    "bitcoin_price_df['_value'].values.tofile('bitcoin_f.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c3421",
   "metadata": {},
   "source": [
    "## Bitcoin Transaction\n",
    "\n",
    "Download URL: https://gz.blockchair.com/bitcoin/transactions/\n",
    "\n",
    "Search and download for day 2022/03/26, or directly download using this link:\n",
    "https://gz.blockchair.com/bitcoin/transactions/blockchair_bitcoin_transactions_20220326.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c363e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_tr_df = pd.read_csv('./bitcoin_transactions.tsv.gz', delimiter='\\t', compression='gzip')\n",
    "bitcoin_tr_df['output_total_usd'].values.tofile('bitcoin_transactions_f.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839191d7",
   "metadata": {},
   "source": [
    "## SSD-HDD Benchmark\n",
    "\n",
    "Download URL: https://www.kaggle.com/datasets/alanjo/ssd-and-hdd-benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14f2e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_df = pd.read_csv('SSD_HDD_benchmarks_v9.csv')\n",
    "ssd_df['diskCapacity'].values.tofile('ssd_hdd_benchmarks_f.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b6dc6",
   "metadata": {},
   "source": [
    "## City Temperature\n",
    "\n",
    "Download URL: https://www.kaggle.com/datasets/sudalairajkumar/daily-temperature-of-major-cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_temp_df = pd.read_csv('city_temperature.csv.gz', compression='gzip', header=None)\n",
    "city_temp_df[2].values.tofile('city_temperature_f.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e82f7",
   "metadata": {},
   "source": [
    "## Basel-Temp & Wind\n",
    "\n",
    "Download URL: https://www.meteoblue.com/en/weather/archive/export/basel_switzerland\n",
    "\n",
    "- Date filters: 2008-01-01 until 2022-01-31   \n",
    "- Boxes selected: Temperature and Wind Speed (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93aad8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basel = pd.read_csv('dataexport_20230415T103128.csv', header=None, skiprows=10)\n",
    "basel_wind = basel[2].values.tofile('basel_wind_t.bin')\n",
    "basel_temp = basel[1].values.tofile('basel_temp.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
